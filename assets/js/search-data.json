{
  
    
        "post0": {
            "title": "Plain Text Tables with Real Data",
            "content": "print(build_title(&#39;COUNTY TEST POSITIVITY REPORTS&#39;)) query_url = &#39;https://idph.illinois.gov/DPHPublicInformation/api/COVID/GetResurgenceData?regionID=8&amp;daysIncluded=5&#39; #+ selectedRegion + &#39;&amp;daysIncluded=&#39; + chartRange page = requests.get(query_url) positivity_rates = page.json()[&#39;CountyTestPositivityReports&#39;] print(&#39;SINGLE SAMPLE&#39;) pprint.pprint(positivity_rates[0]) print() print(&#39;+--+&#39;) print(&#39;| DATE | NAME | POS | TOTAL | AVG | 7 DAY |&#39;) print(&#39;|--|&#39;) for counties in positivity_rates: for i in counties[&#39;countyTestPositivities&#39;]: date = counties[&#39;reportDate&#39;][:10] name = i[&#39;CountyName&#39;] name_fill = &#39; &#39;*(10 - len(name)) positive = i[&#39;positive_test&#39;] positive_fill = &#39; &#39;*(6 - len(str(positive))) total = i[&#39;totalTest&#39;] total_fill = &#39; &#39;*(6 - len(str(total))) daily_avg = round(float(i[&#39;positive_test&#39;]/i[&#39;totalTest&#39;]*100), 1) # positive tests / total tests * 100, then rounded to 1 decimal place daily_avg_fill = &#39; &#39; *(5 - len(str(daily_avg))) seven_day_avg = i[&#39;positivityRollingAvg&#39;] seven_fill = &#39; &#39;*(5 - len(str(seven_day_avg))) print(f&#39;| {date} | {name}{name_fill} | {positive}{positive_fill} | {total}{total_fill} | {daily_avg}{daily_avg_fill} | {seven_day_avg}{seven_fill} |&#39;) print(&#39;+--+&#39;) . - COUNTY TEST POSITIVITY REPORTS - SINGLE SAMPLE {&#39;countyTestPositivities&#39;: [{&#39;CountyName&#39;: &#39;DuPage&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 777, &#39;positivityRollingAvg&#39;: 12.3, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 6411}, {&#39;CountyName&#39;: &#39;Kane&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 517, &#39;positivityRollingAvg&#39;: 16.3, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 3790}], &#39;reportDate&#39;: &#39;2020-11-24T00:00:00&#39;} +--+ | DATE | NAME | POS | TOTAL | AVG | 7 DAY | |--| | 2020-11-24 | DuPage | 777 | 6411 | 12.1 | 12.3 | | 2020-11-24 | Kane | 517 | 3790 | 13.6 | 16.3 | | 2020-11-25 | DuPage | 731 | 6365 | 11.5 | 12.0 | | 2020-11-25 | Kane | 409 | 2847 | 14.4 | 15.5 | | 2020-11-26 | DuPage | 660 | 5301 | 12.5 | 11.8 | | 2020-11-26 | Kane | 433 | 2467 | 17.6 | 15.9 | | 2020-11-27 | DuPage | 712 | 5055 | 14.1 | 11.9 | | 2020-11-27 | Kane | 413 | 2399 | 17.2 | 15.4 | | 2020-11-28 | DuPage | 474 | 4505 | 10.5 | 11.7 | | 2020-11-28 | Kane | 282 | 1568 | 18.0 | 15.0 | | 2020-11-29 | DuPage | 431 | 4188 | 10.3 | 11.4 | | 2020-11-29 | Kane | 265 | 1750 | 15.1 | 15.0 | +--+ . import datetime from datetime import date # TABLE PARAMETERS line_length = 59 print(build_title(&#39;COUNTY TEST POSITIVITY REPORTS&#39;)) query_url = &#39;https://idph.illinois.gov/DPHPublicInformation/api/COVID/GetResurgenceData?regionID=8&amp;daysIncluded=10&#39; #+ selectedRegion + &#39;&amp;daysIncluded=&#39; + chartRange page = requests.get(query_url) positivity_rates = page.json()[&#39;CountyTestPositivityReports&#39;] print(&#39;SINGLE SAMPLE&#39;) pprint.pprint(positivity_rates[-1]) behind = datetime.datetime.strptime(positivity_rates[-1][&#39;reportDate&#39;], &quot;%Y-%m-%dT%H:%M:%S&quot;) behind_str = f&#39;CURRENT DATE: {date.today()} (Report is {(date.today() - behind.date()).days} days *behind*)&#39; behind_fill = &#39; &#39;*(57 - len(behind_str)) print() print(f&#39;+{&quot;=&quot;*line_length}+&#39;) print(f&#39;| {behind_str}{behind_fill} |&#39;) print(f&#39;|{&quot;=&quot;*line_length}|&#39;) print(&#39;| NAME | DATE | POS | TOTAL | AVG | 7 DAY |&#39;) print(f&#39;|{&quot;-&quot;*line_length}|&#39;) number_of_counties = len(positivity_rates[0][&#39;countyTestPositivities&#39;]) for n in range(number_of_counties): print_name = True for counties in positivity_rates: county = counties[&#39;countyTestPositivities&#39;][n]#[n-1] date = counties[&#39;reportDate&#39;][:10] name = county[&#39;CountyName&#39;] if print_name == True else &#39;&#39; name_fill = &#39; &#39;*(10 - len(name)) positive = county[&#39;positive_test&#39;] positive_fill = &#39; &#39;*(6 - len(str(positive))) total = county[&#39;totalTest&#39;] total_fill = &#39; &#39;*(6 - len(str(total))) daily_avg = round(float(county[&#39;positive_test&#39;]/county[&#39;totalTest&#39;]*100), 1) # positive tests / total tests * 100, then rounded to 1 decimal place daily_avg_fill = &#39; &#39; *(5 - len(str(daily_avg))) seven_day_avg = county[&#39;positivityRollingAvg&#39;] seven_fill = &#39; &#39;*(5 - len(str(seven_day_avg))) print(f&#39;| {name}{name_fill} | {date} | {positive}{positive_fill} | {total}{total_fill} | {daily_avg}{daily_avg_fill} | {seven_day_avg}{seven_fill} |&#39;) print_name = False print(f&#39;+{&quot;-&quot;*line_length}+&#39;) . - COUNTY TEST POSITIVITY REPORTS - SINGLE SAMPLE {&#39;countyTestPositivities&#39;: [{&#39;CountyName&#39;: &#39;DuPage&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 431, &#39;positivityRollingAvg&#39;: 11.4, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 4188}, {&#39;CountyName&#39;: &#39;Kane&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 265, &#39;positivityRollingAvg&#39;: 15.0, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 1750}], &#39;reportDate&#39;: &#39;2020-11-29T00:00:00&#39;} +===========================================================+ | CURRENT DATE: 2020-12-02 (Report is 3 days *behind*) | |===========================================================| | NAME | DATE | POS | TOTAL | AVG | 7 DAY | |--| | DuPage | 2020-11-19 | 747 | 5344 | 14.0 | 13.5 | | | 2020-11-20 | 739 | 5755 | 12.8 | 13.2 | | | 2020-11-21 | 629 | 4822 | 13.0 | 13.1 | | | 2020-11-22 | 789 | 6494 | 12.1 | 13.0 | | | 2020-11-23 | 613 | 6652 | 9.2 | 12.3 | | | 2020-11-24 | 777 | 6411 | 12.1 | 12.3 | | | 2020-11-25 | 731 | 6365 | 11.5 | 12.0 | | | 2020-11-26 | 660 | 5301 | 12.5 | 11.8 | | | 2020-11-27 | 712 | 5055 | 14.1 | 11.9 | | | 2020-11-28 | 474 | 4505 | 10.5 | 11.7 | | | 2020-11-29 | 431 | 4188 | 10.3 | 11.4 | +--+ | Kane | 2020-11-19 | 550 | 3792 | 14.5 | 16.4 | | | 2020-11-20 | 706 | 3646 | 19.4 | 16.7 | | | 2020-11-21 | 486 | 2367 | 20.5 | 17.0 | | | 2020-11-22 | 477 | 3126 | 15.3 | 16.8 | | | 2020-11-23 | 323 | 2838 | 11.4 | 16.4 | | | 2020-11-24 | 517 | 3790 | 13.6 | 16.3 | | | 2020-11-25 | 409 | 2847 | 14.4 | 15.5 | | | 2020-11-26 | 433 | 2467 | 17.6 | 15.9 | | | 2020-11-27 | 413 | 2399 | 17.2 | 15.4 | | | 2020-11-28 | 282 | 1568 | 18.0 | 15.0 | | | 2020-11-29 | 265 | 1750 | 15.1 | 15.0 | +--+ .",
            "url": "https://darrida.com/general/tables/data/covid19/2020/12/02/Text-Tables-with-Real-Data.html",
            "relUrl": "/general/tables/data/covid19/2020/12/02/Text-Tables-with-Real-Data.html",
            "date": " • Dec 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Plain Text Tables using Pandas and Real Data",
            "content": "Pull Data into Pandas and Print with Tabulate . Step 1: Pull Parse Data at a High Level . requests is used to query region 8 data from an IL IDPH endpoint | json parses the chunk of data needed | In the output below it shows that the json structure currently is broken into an object that lists the date, then has additional nested objects for all of the individual country data for that date. | . import requests import datetime from pprint import pprint query_url = &#39;https://idph.illinois.gov/DPHPublicInformation/api/COVID/GetResurgenceData?regionID=8&amp;daysIncluded=5&#39; # max is 170 days #+ selectedRegion + &#39;&amp;daysIncluded=&#39; + chartRange page = requests.get(query_url) # Use just the county level positivity reports positivity_rates = page.json()[&#39;CountyTestPositivityReports&#39;] print_title(&#39;2 DAYS OF DATA IN RAW FORM&#39;) pprint(positivity_rates[:2]) . -- 2 DAYS OF DATA IN RAW FORM -- [{&#39;countyTestPositivities&#39;: [{&#39;CountyName&#39;: &#39;DuPage&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 777, &#39;positivityRollingAvg&#39;: 12.3, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 6411}, {&#39;CountyName&#39;: &#39;Kane&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 517, &#39;positivityRollingAvg&#39;: 16.3, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 3790}], &#39;reportDate&#39;: &#39;2020-11-24T00:00:00&#39;}, {&#39;countyTestPositivities&#39;: [{&#39;CountyName&#39;: &#39;DuPage&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 731, &#39;positivityRollingAvg&#39;: 12.0, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 6365}, {&#39;CountyName&#39;: &#39;Kane&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 409, &#39;positivityRollingAvg&#39;: 15.5, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 2847}], &#39;reportDate&#39;: &#39;2020-11-25T00:00:00&#39;}] . Step 2: Flatten Nested Data into Single Level JSON Objects . It&#39;s much easier to import into Pandas when a json object (or any object for that matter, such as a list or tuple) is only one level deep. If data is nested, Pandas&#39; default behavior is to import an entire nested object into a single cell. | The code below takes the existing list of json objects, and pulls each nested piece of county information out to insert into a new list at the top level. While the code creates the new list, line by line, it also inserts the date (converted to a datetime object) into each section as it&#39;s processed. | . | In the output below shows a bit of the new json structure. It&#39;s a list of non-nested json objects, and each one is associated with date. | . flattened_positivity_rates = [] for dates in positivity_rates: for county in dates[&#39;countyTestPositivities&#39;]: county[&#39;date&#39;] = datetime.datetime.strptime(dates[&#39;reportDate&#39;], &quot;%Y-%m-%dT%H:%M:%S&quot;) flattened_positivity_rates.append(county) print_title(&#39;SAME 2 DAYS OF DATA, BUT FLATTENED&#39;) pprint(flattened_positivity_rates[:2]) . - SAME 2 DAYS OF DATA, BUT FLATTENED - [{&#39;CountyName&#39;: &#39;DuPage&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;date&#39;: datetime.datetime(2020, 11, 24, 0, 0), &#39;positive_test&#39;: 777, &#39;positivityRollingAvg&#39;: 12.3, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 6411}, {&#39;CountyName&#39;: &#39;Kane&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;date&#39;: datetime.datetime(2020, 11, 24, 0, 0), &#39;positive_test&#39;: 517, &#39;positivityRollingAvg&#39;: 16.3, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 3790}] . Step 3: Import Data into Pandas, a Little Cleanup, and Reorder Columns . Once each json object in the list is only single level, creating a pandas dataframe out it is a simple one line statement. | One thing that doesn&#39;t come with this dataset is the daily average, but it includes the data needs to calculate it. Again, calculating the data and inserting it as a new column is a single line statement. | Finally, it&#39;s easy to reorder the columns, and leave out unneeded columns in a single statement as well. The output above shows &#39;dailyPositivity&#39; with a value of 0 - which is the same for every json object in the entire dataset. In the reorder columns statement below removing it is a simple as leaving it out. | The results can be seen in the output below. This has the data that&#39;s needed, but it&#39;s still pretty messy. | . import numpy as np import pandas as pd from tabulate import tabulate # Create pandas dataframe region_rates_df = pd.DataFrame(flattened_positivity_rates) # Calulate daily average based on using total tests and the daily positive tests region_rates_df[&#39;daily_avg&#39;] = (region_rates_df[&#39;positive_test&#39;] / region_rates_df[&#39;totalTest&#39;]) * 100 # Reorder Columns region_rates_df = pd.DataFrame(region_rates_df, columns=[&#39;date&#39;, &#39;regionID&#39;, &#39;CountyName&#39;, &#39;totalTest&#39;, &#39;positive_test&#39;, &#39;daily_avg&#39;, &#39;positivityRollingAvg&#39;]) . Step 4: Data Cleanup in Pandas . Renaming columns is a single step, and the order here doesn&#39;t matter (does not change the order in the dataframe) | Cleaning up the date format is simple, especially because when the json was flattened the date was inserted as a datetime formatted object (which was converted to a pandas &quot;timestamp&quot; by the dataframe import process) Above the date may look fine, but that&#39;s because the Jupyter Lab pandas printout removes the hours, minutes, seconds, and microseconds if they are zeros. In reality the actual values looked something like the following: &#39;2020-11-17T00:00:00:00&#39;. | . | The original Daily Avg calculation didn&#39;t specify decimal place at all. .round(2) easy changes that. | Finally, it makes sense to make certain that the rows are sorted by date. | In the out put below, everything looks much better, but the back and forth of DuPage and Kane makes it a little difficult to read. | . region_rates_df.rename( columns={&#39;date&#39;:&#39;Date&#39;, &#39;regionID&#39;:&#39;Region&#39;, &#39;CountyName&#39;:&#39;County&#39;, &#39;totalTest&#39;:&#39;Total Tests&#39;, &#39;daily_avg&#39;:&#39;Daily Avg&#39;, &#39;positivityRollingAvg&#39;:&#39;Rolling Avg&#39;, &#39;positive_test&#39;:&#39;Positive&#39;}, inplace=True ) # Shorten &#39;Date&#39; region_rates_df[&#39;Date&#39;] = region_rates_df[&#39;Date&#39;].dt.strftime(&#39;%m/%d/%Y&#39;) # Round Daily Avg to 2 Decimal Places region_rates_df[&#39;Daily Avg&#39;] = region_rates_df[&#39;Daily Avg&#39;].round(2) # Sort dataframe by &#39;Date&#39; region_rates_df = region_rates_df.sort_values([&#39;Date&#39;]) . Step 5: Print Individual County Date into Plain Text Tables . The Jupyter Lab printouts of dataframes looks pretty nice, but when printing to a console it looks much more rudementary. | Below, .unique() (actually a &#39;numpy&#39; library feature) pulls out the county names represented in the dataframe into a &#39;numpy&#39; array. Similar to objects like lists, the numpy array can be iterated. | . | The print statement does several things: Takes the entire dataframe on each pass (may not be a good idea if the dataframe were very large) and filters it to only include rows with the County name represented by the &#39;name&#39; variable. | Sets headers as &#39;keys&#39;, which just specifies that the headers show up. This parameter works differently depending on the kind of input (i.e., if printing a list of lists where index 0 was a list of headers, headers=list[0] would be used instead) | Sets the table format. Tabulate has a long list of formats available for use. | Removes the index (in this case the index that Pandas uses by default) | . | The output below shows the results of the work above. Each country is printed in it&#39;s own table, with data that is fairly clean and easy to read. | . counties = region_rates_df[&#39;County&#39;].unique() # Print a table for each county for name in counties: # Prints individual country by filtering with a query (i.e., &#39;County&#39; = name) print(tabulate(region_rates_df[(region_rates_df[&#39;County&#39;] == name)], headers = &#39;keys&#39;, tablefmt = (&#39;psql&#39;), showindex=&quot;never&quot;), &#39; n&#39;) . ++-+-+++-++ | Date | Region | County | Total Tests | Positive | Daily Avg | Rolling Avg | |+-+-+++-+| | 11/24/2020 | 8 | DuPage | 6411 | 777 | 12.12 | 12.3 | | 11/25/2020 | 8 | DuPage | 6365 | 731 | 11.48 | 12 | | 11/26/2020 | 8 | DuPage | 5301 | 660 | 12.45 | 11.8 | | 11/27/2020 | 8 | DuPage | 5055 | 712 | 14.09 | 11.9 | | 11/28/2020 | 8 | DuPage | 4505 | 474 | 10.52 | 11.7 | | 11/29/2020 | 8 | DuPage | 4188 | 431 | 10.29 | 11.4 | ++-+-+++-++ ++-+-+++-++ | Date | Region | County | Total Tests | Positive | Daily Avg | Rolling Avg | |+-+-+++-+| | 11/24/2020 | 8 | Kane | 3790 | 517 | 13.64 | 16.3 | | 11/25/2020 | 8 | Kane | 2847 | 409 | 14.37 | 15.5 | | 11/26/2020 | 8 | Kane | 2467 | 433 | 17.55 | 15.9 | | 11/27/2020 | 8 | Kane | 2399 | 413 | 17.22 | 15.4 | | 11/28/2020 | 8 | Kane | 1568 | 282 | 17.98 | 15 | | 11/29/2020 | 8 | Kane | 1750 | 265 | 15.14 | 15 | ++-+-+++-++ . Extra: The Code Works for Any Region or Number of Days . The only hardcoded elements in the previous section were the region number and days in the initial endpoint url. | This means that any region or number of days can be used and the process will work the same. | The output below was produced with the same code by requesting 20 days of data from region 7. Region 7 was used because it also only has 2 counties (easier to use in a blog post), but regions with 10 or more counties work fine as well. | (all of the code above pulled together in one cell can also be viewed by clicking &quot;Expand&quot;) | . import numpy as np import pandas as pd from tabulate import tabulate import requests import datetime, json, sys region = 7 days = 20 query_url = f&#39;https://idph.illinois.gov/DPHPublicInformation/api/COVID/GetResurgenceData?regionID={region}&amp;daysIncluded={days}&#39; # max is 170 days #+ selectedRegion + &#39;&amp;daysIncluded=&#39; + chartRange page = requests.get(query_url) # Use just the county level positivity reports try: positivity_rates = page.json()[&#39;CountyTestPositivityReports&#39;] except json.JSONDecodeError as e: print(&#39;Selected json object not available. It &#39;s possible an invalid region was queried&#39;) raise # Flatten needed json data into a list so it can be imported to a pandas dataframe flattened_positivity_rates = [] for dates in positivity_rates: for county in dates[&#39;countyTestPositivities&#39;]: county[&#39;date&#39;] = datetime.datetime.strptime(dates[&#39;reportDate&#39;], &quot;%Y-%m-%dT%H:%M:%S&quot;) flattened_positivity_rates.append(county) # Create pandas dataframe region_rates_df = pd.DataFrame(flattened_positivity_rates) # Calulate daily average based on using total tests and the daily positive tests region_rates_df[&#39;daily_avg&#39;] = (region_rates_df[&#39;positive_test&#39;] / region_rates_df[&#39;totalTest&#39;]) * 100 # Reorder Columns region_rates_df = pd.DataFrame(region_rates_df, columns=[&#39;date&#39;, &#39;regionID&#39;, &#39;CountyName&#39;, &#39;totalTest&#39;, &#39;positive_test&#39;, &#39;daily_avg&#39;, &#39;positivityRollingAvg&#39;]) # Rename Columns region_rates_df.rename( columns={&#39;date&#39;:&#39;Date&#39;, &#39;regionID&#39;:&#39;Region&#39;, &#39;CountyName&#39;:&#39;County&#39;, &#39;totalTest&#39;:&#39;Total Tests&#39;, &#39;daily_avg&#39;:&#39;Daily Avg&#39;, &#39;positivityRollingAvg&#39;:&#39;Rolling Avg&#39;, &#39;positive_test&#39;:&#39;Positive&#39;}, inplace=True ) # Shorten &#39;Date&#39; region_rates_df[&#39;Date&#39;] = region_rates_df[&#39;Date&#39;].dt.strftime(&#39;%m/%d/%Y&#39;) # Round Daily Avg to 2 Decimal Places region_rates_df[&#39;Daily Avg&#39;] = region_rates_df[&#39;Daily Avg&#39;].round(2) # Sort dataframe by &#39;Date&#39; region_rates_df = region_rates_df.sort_values([&#39;Date&#39;]) # Create array of unique county names counties = region_rates_df[&#39;County&#39;].unique() # Print a table for each county for name in counties: # Prints individual country by filtering with a query (i.e., &#39;County&#39; = name) print(tabulate(region_rates_df[(region_rates_df[&#39;County&#39;] == name)], headers = &#39;keys&#39;, tablefmt = (&#39;psql&#39;)), &#39; n&#39;) . . +-++-+-+++-++ | | Date | Region | County | Total Tests | Positive | Daily Avg | Rolling Avg | |-++-+-+++-+| | 0 | 11/09/2020 | 7 | Kankakee | 761 | 203 | 26.68 | 19.2 | | 2 | 11/10/2020 | 7 | Kankakee | 1383 | 220 | 15.91 | 18.8 | | 4 | 11/11/2020 | 7 | Kankakee | 1450 | 242 | 16.69 | 19.1 | | 6 | 11/12/2020 | 7 | Kankakee | 1009 | 257 | 25.47 | 20.1 | | 8 | 11/13/2020 | 7 | Kankakee | 1640 | 353 | 21.52 | 20.3 | | 10 | 11/14/2020 | 7 | Kankakee | 1143 | 343 | 30.01 | 21.9 | | 12 | 11/15/2020 | 7 | Kankakee | 1187 | 326 | 27.46 | 22.7 | | 14 | 11/16/2020 | 7 | Kankakee | 642 | 159 | 24.77 | 22.5 | | 16 | 11/17/2020 | 7 | Kankakee | 1268 | 189 | 14.91 | 22.4 | | 18 | 11/18/2020 | 7 | Kankakee | 1570 | 222 | 14.14 | 21.9 | | 20 | 11/19/2020 | 7 | Kankakee | 1217 | 185 | 15.2 | 20.5 | | 22 | 11/20/2020 | 7 | Kankakee | 2067 | 265 | 12.82 | 18.6 | | 24 | 11/21/2020 | 7 | Kankakee | 948 | 251 | 26.48 | 17.9 | | 26 | 11/22/2020 | 7 | Kankakee | 1072 | 239 | 22.29 | 17.2 | | 28 | 11/23/2020 | 7 | Kankakee | 1024 | 150 | 14.65 | 16.4 | | 30 | 11/24/2020 | 7 | Kankakee | 1753 | 225 | 12.84 | 15.9 | | 32 | 11/25/2020 | 7 | Kankakee | 1931 | 231 | 11.96 | 15.4 | | 34 | 11/26/2020 | 7 | Kankakee | 877 | 188 | 21.44 | 16 | | 36 | 11/27/2020 | 7 | Kankakee | 601 | 109 | 18.14 | 17 | | 38 | 11/28/2020 | 7 | Kankakee | 1027 | 169 | 16.46 | 15.8 | | 40 | 11/29/2020 | 7 | Kankakee | 756 | 91 | 12.04 | 14.6 | +-++-+-+++-++ +-++-+-+++-++ | | Date | Region | County | Total Tests | Positive | Daily Avg | Rolling Avg | |-++-+-+++-+| | 1 | 11/09/2020 | 7 | Will | 4663 | 863 | 18.51 | 18.3 | | 3 | 11/10/2020 | 7 | Will | 4160 | 808 | 19.42 | 18.5 | | 5 | 11/11/2020 | 7 | Will | 4237 | 902 | 21.29 | 19.2 | | 7 | 11/12/2020 | 7 | Will | 4149 | 831 | 20.03 | 19.7 | | 9 | 11/13/2020 | 7 | Will | 4210 | 817 | 19.41 | 19.6 | | 11 | 11/14/2020 | 7 | Will | 3461 | 821 | 23.72 | 19.9 | | 13 | 11/15/2020 | 7 | Will | 4014 | 761 | 18.96 | 20.1 | | 15 | 11/16/2020 | 7 | Will | 4316 | 821 | 19.02 | 20.2 | | 17 | 11/17/2020 | 7 | Will | 3466 | 643 | 18.55 | 20.1 | | 19 | 11/18/2020 | 7 | Will | 4186 | 752 | 17.96 | 19.6 | | 21 | 11/19/2020 | 7 | Will | 4093 | 826 | 20.18 | 19.6 | | 23 | 11/20/2020 | 7 | Will | 4600 | 821 | 17.85 | 19.4 | | 25 | 11/21/2020 | 7 | Will | 3408 | 638 | 18.72 | 18.7 | | 27 | 11/22/2020 | 7 | Will | 4131 | 682 | 16.51 | 18.4 | | 29 | 11/23/2020 | 7 | Will | 3870 | 624 | 16.12 | 18 | | 31 | 11/24/2020 | 7 | Will | 4729 | 768 | 16.24 | 17.6 | | 33 | 11/25/2020 | 7 | Will | 4262 | 731 | 17.15 | 17.5 | | 35 | 11/26/2020 | 7 | Will | 3065 | 625 | 20.39 | 17.4 | | 37 | 11/27/2020 | 7 | Will | 3568 | 658 | 18.44 | 17.5 | | 39 | 11/28/2020 | 7 | Will | 2673 | 490 | 18.33 | 17.4 | | 41 | 11/29/2020 | 7 | Will | 2631 | 381 | 14.48 | 17.2 | +-++-+-+++-++ .",
            "url": "https://darrida.com/general/pandas/covid19/tables/data/2020/12/02/Text-Tables-using-Pandas-and-Real-Data.html",
            "relUrl": "/general/pandas/covid19/tables/data/2020/12/02/Text-Tables-using-Pandas-and-Real-Data.html",
            "date": " • Dec 2, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Advanced Tables with Pulled Data",
            "content": "NOTE: Major Work-in-Progress. Maybe not be coherent, and much of the work needs to be updated using tabulate rather than generating tables from scratch. This post was originally going to walk through the basics of building plain text tables from scratch using real data from the outset, but it got too complicated to quickly. A separate post ended up being written for that purpose. . Basic Table w/ Manual Column Size Control . The sample data is Covid-19 region 8 information pulled from the Illinois Department of Public Health. More data than is needed comes with this HTTP request. | Specific data used is for the County Test Positivity Reports. | . | Code description: line 8: printout of sample json object to show what the raw data looks like | line 11: Simplest form of creating a header: string printing of strings | line 14: The json object, &#39;countyTestPositivities&#39;, under &#39;CountryTestPositivityReports&#39; contains a list of json objects inside - one for each county. The nested for loop takes the first object, loops through the nested list, then moves onto the next object and nested list. | lines 16-26: rudementry data clean up for the plain text table This clean up involves both reformatting of data, but also ensuring that the cells in the table all line up. | Example - Data Formatting: &quot;date&quot; - counties[&#39;reportDate&#39;][:10] takes the long datetime string and moves all of the time characters. It does this by cutting out any characters between the 10th character ([9]) in the string. There are better ways to do this using the datetime library, but this works as well. | Example - Table Formatting: &quot;name&quot; We want the name column to always be 1 characters wide. | The first step is the basic action of setting the name variable from the pulled data | The second step is the following, in reverse order of the code in line 19: (1) count (len) the number of characters in the name string | (2) subtract that number from the desired column width, which is 10 in this case (if the name is &quot;Kane&quot;, then that would be 10 - 4 = 6) | (3) populate &quot;name_fill&quot; with a string of spaces the length of the result from the previous step (if the name is &quot;Kane&quot;, then that would be a string of 6 spaces) | . | . | The column filler variable is setup for &quot;name&quot;, &quot;positive&quot;, &quot;total&quot;, &quot;daily_avg&quot;, and &quot;seven_day_avg&quot; | . | line 27: The content portion of the table is printed one line at a time using a combination of bars, spaces, and the pair of data variable and filler variable | line 28: Closes the bottm of the table with another string to match the header | . | See the output further below for a visual of the raw data example, and the resulting plain text table | . print(build_title(&#39;COUNTY TEST POSITIVITY REPORTS&#39;)) query_url = &#39;https://idph.illinois.gov/DPHPublicInformation/api/COVID/GetResurgenceData?regionID=8&amp;daysIncluded=5&#39; #+ selectedRegion + &#39;&amp;daysIncluded=&#39; + chartRange page = requests.get(query_url) positivity_rates = page.json()[&#39;CountyTestPositivityReports&#39;] print(&#39;SINGLE SAMPLE&#39;) pprint.pprint(positivity_rates[0]) print() print(&#39;+--+&#39;) print(&#39;| DATE | NAME | POS | TOTAL | AVG | 7 DAY |&#39;) print(&#39;|--|&#39;) for counties in positivity_rates: for i in counties[&#39;countyTestPositivities&#39;]: date = counties[&#39;reportDate&#39;][:10] name = i[&#39;CountyName&#39;] name_fill = &#39; &#39;*(10 - len(name)) positive = i[&#39;positive_test&#39;] positive_fill = &#39; &#39;*(6 - len(str(positive))) total = i[&#39;totalTest&#39;] total_fill = &#39; &#39;*(6 - len(str(total))) daily_avg = round(float(i[&#39;positive_test&#39;]/i[&#39;totalTest&#39;]*100), 1) # positive tests / total tests * 100, then rounded to 1 decimal place daily_avg_fill = &#39; &#39; *(5 - len(str(daily_avg))) seven_day_avg = i[&#39;positivityRollingAvg&#39;] seven_fill = &#39; &#39;*(5 - len(str(seven_day_avg))) print(f&#39;| {date} | {name}{name_fill} | {positive}{positive_fill} | {total}{total_fill} | {daily_avg}{daily_avg_fill} | {seven_day_avg}{seven_fill} |&#39;) print(&#39;+--+&#39;) . - COUNTY TEST POSITIVITY REPORTS - SINGLE SAMPLE {&#39;countyTestPositivities&#39;: [{&#39;CountyName&#39;: &#39;DuPage&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 789, &#39;positivityRollingAvg&#39;: 13.0, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 6494}, {&#39;CountyName&#39;: &#39;Kane&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 477, &#39;positivityRollingAvg&#39;: 16.8, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 3126}], &#39;reportDate&#39;: &#39;2020-11-22T00:00:00&#39;} +--+ | DATE | NAME | POS | TOTAL | AVG | 7 DAY | |--| | 2020-11-22 | DuPage | 789 | 6494 | 12.1 | 13.0 | | 2020-11-22 | Kane | 477 | 3126 | 15.3 | 16.8 | | 2020-11-23 | DuPage | 613 | 6652 | 9.2 | 12.3 | | 2020-11-23 | Kane | 323 | 2838 | 11.4 | 16.4 | | 2020-11-24 | DuPage | 777 | 6411 | 12.1 | 12.3 | | 2020-11-24 | Kane | 517 | 3790 | 13.6 | 16.3 | | 2020-11-25 | DuPage | 731 | 6365 | 11.5 | 12.0 | | 2020-11-25 | Kane | 409 | 2847 | 14.4 | 15.5 | | 2020-11-26 | DuPage | 660 | 5301 | 12.5 | 11.8 | | 2020-11-26 | Kane | 433 | 2467 | 17.6 | 15.9 | | 2020-11-27 | DuPage | 712 | 5055 | 14.1 | 11.9 | | 2020-11-27 | Kane | 413 | 2399 | 17.2 | 15.4 | +--+ . Basic Table with Cleaned Up Data (and also w/ Manual Column Size Control) . import datetime from datetime import date # TABLE PARAMETERS line_length = 59 print(build_title(&#39;COUNTY TEST POSITIVITY REPORTS&#39;)) query_url = &#39;https://idph.illinois.gov/DPHPublicInformation/api/COVID/GetResurgenceData?regionID=8&amp;daysIncluded=10&#39; #+ selectedRegion + &#39;&amp;daysIncluded=&#39; + chartRange page = requests.get(query_url) positivity_rates = page.json()[&#39;CountyTestPositivityReports&#39;] print(&#39;SINGLE SAMPLE&#39;) pprint.pprint(positivity_rates[-1]) behind = datetime.datetime.strptime(positivity_rates[-1][&#39;reportDate&#39;], &quot;%Y-%m-%dT%H:%M:%S&quot;) behind_str = f&#39;CURRENT DATE: {date.today()} (Report is {(date.today() - behind.date()).days} days *behind*)&#39; behind_fill = &#39; &#39;*(57 - len(behind_str)) print() print(f&#39;+{&quot;=&quot;*line_length}+&#39;) print(f&#39;| {behind_str}{behind_fill} |&#39;) print(f&#39;|{&quot;=&quot;*line_length}|&#39;) print(&#39;| NAME | DATE | POS | TOTAL | AVG | 7 DAY |&#39;) print(f&#39;|{&quot;-&quot;*line_length}|&#39;) number_of_counties = len(positivity_rates[0][&#39;countyTestPositivities&#39;]) for n in range(number_of_counties): print_name = True for counties in positivity_rates: county = counties[&#39;countyTestPositivities&#39;][n]#[n-1] date = counties[&#39;reportDate&#39;][:10] name = county[&#39;CountyName&#39;] if print_name == True else &#39;&#39; name_fill = &#39; &#39;*(10 - len(name)) positive = county[&#39;positive_test&#39;] positive_fill = &#39; &#39;*(6 - len(str(positive))) total = county[&#39;totalTest&#39;] total_fill = &#39; &#39;*(6 - len(str(total))) daily_avg = round(float(county[&#39;positive_test&#39;]/county[&#39;totalTest&#39;]*100), 1) # positive tests / total tests * 100, then rounded to 1 decimal place daily_avg_fill = &#39; &#39; *(5 - len(str(daily_avg))) seven_day_avg = county[&#39;positivityRollingAvg&#39;] seven_fill = &#39; &#39;*(5 - len(str(seven_day_avg))) print(f&#39;| {name}{name_fill} | {date} | {positive}{positive_fill} | {total}{total_fill} | {daily_avg}{daily_avg_fill} | {seven_day_avg}{seven_fill} |&#39;) print_name = False print(f&#39;+{&quot;-&quot;*line_length}+&#39;) . - COUNTY TEST POSITIVITY REPORTS - SINGLE SAMPLE {&#39;countyTestPositivities&#39;: [{&#39;CountyName&#39;: &#39;DuPage&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 712, &#39;positivityRollingAvg&#39;: 11.9, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 5055}, {&#39;CountyName&#39;: &#39;Kane&#39;, &#39;dailyPositivity&#39;: 0.0, &#39;positive_test&#39;: 413, &#39;positivityRollingAvg&#39;: 15.4, &#39;regionID&#39;: 8, &#39;totalTest&#39;: 2399}], &#39;reportDate&#39;: &#39;2020-11-27T00:00:00&#39;} +===========================================================+ | CURRENT DATE: 2020-11-30 (Report is 3 days *behind*) | |===========================================================| | NAME | DATE | POS | TOTAL | AVG | 7 DAY | |--| | DuPage | 2020-11-17 | 695 | 5626 | 12.4 | 13.5 | | | 2020-11-18 | 817 | 6029 | 13.6 | 13.5 | | | 2020-11-19 | 747 | 5344 | 14.0 | 13.5 | | | 2020-11-20 | 739 | 5755 | 12.8 | 13.2 | | | 2020-11-21 | 629 | 4822 | 13.0 | 13.1 | | | 2020-11-22 | 789 | 6494 | 12.1 | 13.0 | | | 2020-11-23 | 613 | 6652 | 9.2 | 12.3 | | | 2020-11-24 | 777 | 6411 | 12.1 | 12.3 | | | 2020-11-25 | 731 | 6365 | 11.5 | 12.0 | | | 2020-11-26 | 660 | 5301 | 12.5 | 11.8 | | | 2020-11-27 | 712 | 5055 | 14.1 | 11.9 | +--+ | Kane | 2020-11-17 | 458 | 3236 | 14.2 | 16.7 | | | 2020-11-18 | 639 | 3143 | 20.3 | 17.1 | | | 2020-11-19 | 550 | 3792 | 14.5 | 16.4 | | | 2020-11-20 | 706 | 3646 | 19.4 | 16.7 | | | 2020-11-21 | 486 | 2367 | 20.5 | 17.0 | | | 2020-11-22 | 477 | 3126 | 15.3 | 16.8 | | | 2020-11-23 | 323 | 2838 | 11.4 | 16.4 | | | 2020-11-24 | 517 | 3790 | 13.6 | 16.3 | | | 2020-11-25 | 409 | 2847 | 14.4 | 15.5 | | | 2020-11-26 | 433 | 2467 | 17.6 | 15.9 | | | 2020-11-27 | 413 | 2399 | 17.2 | 15.4 | +--+ . Tables Created with tabulate . Regular tabulate table . Pandas tabulate table . tablefmt options: plain, simple, github, grid, fancy_grid, pipe, orgtbl, jira, fpresto, pretty, psql, rst, mediawiki, moinmoin, youtrack, html, latex, latex_raw, latex_booktabs, textile | . import numpy as np import pandas as pd from tabulate import tabulate import requests import datetime query_url = &#39;https://idph.illinois.gov/DPHPublicInformation/api/COVID/GetResurgenceData?regionID=8&amp;daysIncluded=10&#39; # max is 170 days #+ selectedRegion + &#39;&amp;daysIncluded=&#39; + chartRange page = requests.get(query_url) positivity_rates = page.json()[&#39;CountyTestPositivityReports&#39;] flattened_positivity_rates = [] for dates in positivity_rates: for county in dates[&#39;countyTestPositivities&#39;]: county[&#39;date&#39;] = datetime.datetime.strptime(dates[&#39;reportDate&#39;], &quot;%Y-%m-%dT%H:%M:%S&quot;) flattened_positivity_rates.append(county) county_test_pos_rates_df = pd.DataFrame(flattened_positivity_rates) county_test_pos_rates_df[&#39;daily_avg&#39;] = (county_test_pos_rates_df[&#39;positive_test&#39;] / county_test_pos_rates_df[&#39;totalTest&#39;]) * 100 print(tabulate(county_test_pos_rates_df.sort_values([&#39;CountyName&#39;, &#39;date&#39;]), headers = &#39;keys&#39;, tablefmt = &#39;psql&#39;)) . +-+--+-+--++-+++-+ | | CountyName | totalTest | positive_test | positivityRollingAvg | dailyPositivity | regionID | date | daily_avg | |-+--+-+--++-+++-| | 0 | DuPage | 5626 | 695 | 13.5 | 0 | 8 | 2020-11-17 00:00:00 | 12.3534 | | 2 | DuPage | 6029 | 817 | 13.5 | 0 | 8 | 2020-11-18 00:00:00 | 13.5512 | | 4 | DuPage | 5344 | 747 | 13.5 | 0 | 8 | 2020-11-19 00:00:00 | 13.9783 | | 6 | DuPage | 5755 | 739 | 13.2 | 0 | 8 | 2020-11-20 00:00:00 | 12.841 | | 8 | DuPage | 4822 | 629 | 13.1 | 0 | 8 | 2020-11-21 00:00:00 | 13.0444 | | 10 | DuPage | 6494 | 789 | 13 | 0 | 8 | 2020-11-22 00:00:00 | 12.1497 | | 12 | DuPage | 6652 | 613 | 12.3 | 0 | 8 | 2020-11-23 00:00:00 | 9.21527 | | 14 | DuPage | 6411 | 777 | 12.3 | 0 | 8 | 2020-11-24 00:00:00 | 12.1198 | | 16 | DuPage | 6365 | 731 | 12 | 0 | 8 | 2020-11-25 00:00:00 | 11.4847 | | 18 | DuPage | 5301 | 660 | 11.8 | 0 | 8 | 2020-11-26 00:00:00 | 12.4505 | | 20 | DuPage | 5055 | 712 | 11.9 | 0 | 8 | 2020-11-27 00:00:00 | 14.0851 | | 1 | Kane | 3236 | 458 | 16.7 | 0 | 8 | 2020-11-17 00:00:00 | 14.1533 | | 3 | Kane | 3143 | 639 | 17.1 | 0 | 8 | 2020-11-18 00:00:00 | 20.3309 | | 5 | Kane | 3792 | 550 | 16.4 | 0 | 8 | 2020-11-19 00:00:00 | 14.5042 | | 7 | Kane | 3646 | 706 | 16.7 | 0 | 8 | 2020-11-20 00:00:00 | 19.3637 | | 9 | Kane | 2367 | 486 | 17 | 0 | 8 | 2020-11-21 00:00:00 | 20.5323 | | 11 | Kane | 3126 | 477 | 16.8 | 0 | 8 | 2020-11-22 00:00:00 | 15.2591 | | 13 | Kane | 2838 | 323 | 16.4 | 0 | 8 | 2020-11-23 00:00:00 | 11.3813 | | 15 | Kane | 3790 | 517 | 16.3 | 0 | 8 | 2020-11-24 00:00:00 | 13.6412 | | 17 | Kane | 2847 | 409 | 15.5 | 0 | 8 | 2020-11-25 00:00:00 | 14.366 | | 19 | Kane | 2467 | 433 | 15.9 | 0 | 8 | 2020-11-26 00:00:00 | 17.5517 | | 21 | Kane | 2399 | 413 | 15.4 | 0 | 8 | 2020-11-27 00:00:00 | 17.2155 | +-+--+-+--++-+++-+ . Aside: Same Pandas Data Visualized . import matplotlib.pyplot as plt import matplotlib as mpl from datetime import datetime import numpy as np import pandas as pd import requests query_url = &#39;https://idph.illinois.gov/DPHPublicInformation/api/COVID/GetResurgenceData?regionID=8&amp;daysIncluded=90&#39; # max is 170 days #+ selectedRegion + &#39;&amp;daysIncluded=&#39; + chartRange page = requests.get(query_url) positivity_rates = page.json()[&#39;CountyTestPositivityReports&#39;] flattened_positivity_rates = [] for dates in positivity_rates: for county in dates[&#39;countyTestPositivities&#39;]: county[&#39;date&#39;] = datetime.strptime(dates[&#39;reportDate&#39;], &quot;%Y-%m-%dT%H:%M:%S&quot;) flattened_positivity_rates.append(county) county_test_pos_rates_df = pd.DataFrame(flattened_positivity_rates) county_test_pos_rates_df[&#39;daily_avg&#39;] = (county_test_pos_rates_df[&#39;positive_test&#39;] / county_test_pos_rates_df[&#39;totalTest&#39;]) * 100 mpl.rcParams[&#39;figure.dpi&#39;] = 150 county_test_pos_rates_df.plot(y=[&#39;daily_avg&#39;, &#39;positivityRollingAvg&#39;], x=&#39;date&#39;); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-30T23:07:26.145310 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ # SAME GRAPH, BUT WITH INTERACTIVE ADJUSTMENTS import matplotlib.pyplot as plt import matplotlib as mpl from ipywidgets import interact from datetime import datetime, timedelta import numpy as np import pandas as pd import requests query_url = &#39;https://idph.illinois.gov/DPHPublicInformation/api/COVID/GetResurgenceData?regionID=8&amp;daysIncluded=90&#39; # max is 170 days #+ selectedRegion + &#39;&amp;daysIncluded=&#39; + chartRange page = requests.get(query_url) positivity_rates = page.json()[&#39;CountyTestPositivityReports&#39;] flattened_positivity_rates = [] for dates in positivity_rates: for county in dates[&#39;countyTestPositivities&#39;]: county[&#39;date&#39;] = datetime.strptime(dates[&#39;reportDate&#39;], &quot;%Y-%m-%dT%H:%M:%S&quot;) flattened_positivity_rates.append(county) county_test_pos_rates_df = pd.DataFrame(flattened_positivity_rates) county_test_pos_rates_df[&#39;daily_avg&#39;] = (county_test_pos_rates_df[&#39;positive_test&#39;] / county_test_pos_rates_df[&#39;totalTest&#39;]) * 100 @interact(dpi=(100, 500), days=(30, 93, 7)) def graph(dpi=100, days=93): mpl.rcParams[&#39;figure.dpi&#39;] = dpi number_prev_days = datetime.today() - timedelta (days) filtered_df=county_test_pos_rates_df.query(f&quot;date &lt;= &#39;{datetime.today()}&#39; and date &gt;= &#39;{number_prev_days}&#39;&quot;) filtered_df.plot(y=[&#39;daily_avg&#39;, &#39;positivityRollingAvg&#39;], x=&#39;date&#39;) . .",
            "url": "https://darrida.com/general/2020/11/30/Advanced-Tables-with-Pulled-Data.html",
            "relUrl": "/general/2020/11/30/Advanced-Tables-with-Pulled-Data.html",
            "date": " • Nov 30, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Print Simple Tables",
            "content": "Manually Created Tables . Creating plain text tables from scratch is tedious, especially if they require a lot of flexibility. | Libraries exist that remove all of this work (one is explored further below), but with all programming libraries it&#39;s helpful (if not very important) to understand the general concept of what is happening behind the scenes. | This sections covers that &quot;basic concept&quot; part. It walks through sample methods for creating tables (from crude to dynamic). | . Crude separators . Sample Data 1 . table_list = [ [&#39;INDEX&#39;, &#39;COLUMN1&#39;, &#39;COLUMN2&#39;, &#39;COLUMN3&#39;], [&#39;1&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;], [&#39;2&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;], [&#39;3&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;] ] . At the simplest level, you could just print out each sublist (for example), with each item separated by bars. The issue with this approach is that the columns won&#39;t be lined up at all. In this case lists 2-4 are lined up, but not the column headers. | . for item in table_list: row = f&#39;| {item[0]} | {item[1]} | {item[2]} | {item[3]} |&#39; print(row) . | INDEX | COLUMN1 | COLUMN2 | COLUMN3 | | 1 | A | B | C | | 2 | D | E | F | | 3 | G | H | I | . Basic column width . A basic fix for this would be decided on a column width, and make sure that each string was that long using a raw equation. | In the case below, the string length for the column is 10 characters -- the equation is similar to: &#39; &#39; * (10 - len(string_variable)) Working from the outside in, this does the following: string_length = len(string_variable) =&gt; counts the number of characters in the string that contains the value | length_diff = 10 - string_length =&gt; subtracts the result of step 1 from ten | string_fill = &#39; &#39; * length_diff =&gt; mutliplies a space character by the length difference between the orginal value and the required column length | `final_str = string_variable + string_fill =&gt; lenth will meet the column width requirement | | . | The approach is used below. Each item in the lists takes the original string, calculates required filler space characters, then builds the new variable. | . for item in table_list: # HORIZONAL LINES ADDED FOR REASONS print(&#39;++&#39;) item0 = item[0] + &quot; &quot; * (10 - len(item[0])) item1 = item[1] + &quot; &quot; * (10 - len(item[1])) item2 = item[2] + &quot; &quot; * (10 - len(item[2])) item3 = item[3] + &quot; &quot; * (10 - len(item[3])) row = f&#39;| {item0} | {item1} | {item2} | {item3} |&#39; print(row) print(&#39;++&#39;) . ++ | INDEX | COLUMN1 | COLUMN2 | COLUMN3 | ++ | 1 | A | B | C | ++ | 2 | D | E | F | ++ | 3 | G | H | I | ++ . The output above now resembles an actual table of data, but it the current approach comes with drawbacks. For example: What happens if a string is wider than the desired string length of the column width? | . Dynamic Column Width . Sample Data 2 (increases column 4 in row 4 beyond 10 characters) . table_list = [ [&#39;INDEX&#39;, &#39;COLUMN1&#39;, &#39;COLUMN2&#39;, &#39;COLUMN3&#39;], [&#39;1&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;], [&#39;2&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;], [&#39;3&#39;, &#39;G&#39;, &#39;9999999999999&#39;, &#39;I&#39;] ] . In the next example, each columns width is dynamically calulated based on the width of the longest string for that column | Doing this requires interating over each index position in every row to calculate the max length - then storing that information in another list (width_list) | The index positions in width_list match up with column index positions, so width_list[n] can be directly replace the &quot;10&quot; used above | NOTE: The horizontal line is now calculated as well. There is no magic in the calculation. Just trial and error until I figured it out. | . # CREATE EMPTY LIST FOR COLUMN WIDTHS width_list = [] # ITERATE OVER `table_list`, ONCE FOR EACH LIST/ROW # - Sets an index of 0, which is increase each time an index position (representing a column) is fully accounted for throughout `table_list` index = 0 while index &lt; len(table_list): # FOR EACH INDEX POSITION ITERATE OVER THAT INDEX IN EVER LIST TO FIND LONGEST STRING for row in table_list: try: if len(row[index]) &gt; width_list[index]: width_list[index] = len(row[index]) # HANDLES EXCEPTIONS THROWN FOR THE FIRST TIME THE CODE ATTEMPTS TO SET/CHANGE EACH INDEX IN `width_list` # - Creates the index position by appending a 0, then sets that position as the length of the current value being evaluated except IndexError as e: if str(e) == &#39;list index out of range&#39;: width_list.append(0) width_list[index] = len(row[index]) index += 1 # RESULT IS LIST WITH LONGEST STRING IN EACH COLUMN print(&#39;Longest string in each column:&#39;, width_list, &#39; n&#39;) # CALCULATE HORIZONTAL LINES BASED ON `width_list` row_length = len(width_list)*2 + (len(width_list) - 1) + sum(width_list) # BUILD LINE BASED ON LENGTH CALCULATION line = f&#39;+{&quot;-&quot; * row_length}+&#39; # BUILD AND PRINT TABLE for item in table_list: item0 = item[0] + &#39; &#39; * (width_list[0] - len(item[0])) item1 = item[1] + &#39; &#39; * (width_list[1] - len(item[1])) item2 = item[2] + &#39; &#39; * (width_list[2] - len(item[2])) item3 = item[3] + &#39; &#39; * (width_list[3] - len(item[3])) print(line) print(f&#39;| {item0} | {item1} | {item2} | {item3} |&#39;) print(line) . Longest string in each column: [5, 7, 13, 7] +-+ | INDEX | COLUMN1 | COLUMN2 | COLUMN3 | +-+ | 1 | A | B | C | +-+ | 2 | D | E | F | +-+ | 3 | G | 9999999999999 | I | +-+ . Dynamic Number of Columns . Sample Data 3 (increases number of rows and columns) . table_list = [ [&#39;INDEX&#39;, &#39;COLUMN1&#39;, &#39;COLUMN2&#39;, &#39;COLUMN3&#39;, &#39;COLUMN4&#39;, &#39;COLUMN5&#39;], [&#39;1&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;CB&#39;, &#39;CC&#39;], [&#39;2&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;FB&#39;, &#39;FC&#39;], [&#39;3&#39;, &#39;G&#39;, &#39;9999999999999&#39;, &#39;I&#39;, &#39;IB&#39;, &#39;IC&#39;], [&#39;4&#39;, &#39;!&#39;, &#39;@&#39;, &#39;#&#39;, &#39;$&#39;, &#39;%&#39;], ] . Every example up to this point assumes that the width of the table is know | The example below has dynamically to populate the width_list (simply involves adding [0] to the while statement - which comes with its own limitations), and dynamically builds each row (rather than index positions being hard coded | . # CREATE EMPTY LIST FOR COLUMN WIDTHS width_list = [] # VALIDATES THAT EVERY LIST/ROW IS THE SAME LENGTH (required for valid table) # - The map function runs `len` against every list in table_list and records the results in a map object # - Wrapping `list()` around the map function converts the map function to a list of int representing list lengths lengths = list(map(len, table_list)) # - The list comprehention tests the first value in `lengths` against every other value in the list. # - If the test matches, True, else False. # - The list function converts the map object to a list # - The if statement around the comprehention checks if False exists anywhere in the resulting list. # - If False exists one or more times `same` is set to False (which will skip the result of the code). # - If False does not exist `same` set to True same = False if False in [lengths[0] == x for x in lengths] else True # ITERATE OVER `table_list`, ONCE FOR EACH LIST/ROW # - Sets an index of 0, which is increase each time an index position (representing a column) is fully accounted for throughout `table_list` if same == True: index = 0 while index &lt; len(table_list[0]): # FOR EACH INDEX POSITION ITERATE OVER THAT INDEX IN EVER LIST TO FIND LONGEST STRING for row in table_list: try: if len(row[index]) &gt; width_list[index]: width_list[index] = len(row[index]) # HANDLES EXCEPTIONS THROWN FOR THE FIRST TIME THE CODE ATTEMPTS TO SET/CHANGE EACH INDEX IN `width_list` # - Creates the index position by appending a 0, then sets that position as the length of the current value being evaluated except IndexError as e: if str(e) == &#39;list index out of range&#39;: width_list.append(0) width_list[index] = len(row[index]) index += 1 # RESULT IS LIST WITH LONGEST STRING IN EACH COLUMN print(&#39;Longest string in each column:&#39;, width_list, &#39; n&#39;) # CALCULATE HORIZONTAL LINES BASED ON `width_list` row_length = len(width_list)*2 + (len(width_list) - 1) + sum(width_list) # BUILD LINE BASED ON LENGTH CALCULATION line = f&#39;+{&quot;-&quot; * row_length}+&#39; # BUILD AND PRINT TABLE for list_row in table_list: width_index = 0 row = &#39;&#39; # THE BUILD RELATED STATEMENTS ARE NOW DYNAMIC INSTEAD OF HARDCODED for item in list_row: item_str = &quot; &quot; + item + &quot; &quot; * (width_list[width_index] - len(item)) + &quot; &quot; row = row + &#39;|&#39; + item_str width_index += 1 print(line) print(row + &#39;|&#39;) print(line) else: print(&#39;Not all rows are the same length. Valid table can &#39;t be built.&#39;) . Longest string in each column: [5, 7, 13, 7, 7, 7] ++ | INDEX | COLUMN1 | COLUMN2 | COLUMN3 | COLUMN4 | COLUMN5 | ++ | 1 | A | B | C | CB | CC | ++ | 2 | D | E | F | FB | FC | ++ | 3 | G | 9999999999999 | I | IB | IC | ++ | 4 | ! | @ | # | $ | % | ++ . This gets the job, but it is a lot of work just to print a plain text table | Fortunately, there is a library that does a lot of this work behind the scenes | . Tables Created with Tabulate . PyPI: https://pypi.org/project/tabulate/ | Conda-Forge: https://anaconda.org/conda-forge/tabulatehttps://anaconda.org/conda-forge/tabulate | Github: https://github.com/astanin/python-tabulate (includes docs) | . Sample Data 3 (same as previous example) . table_list = [ [&#39;INDEX&#39;, &#39;COLUMN1&#39;, &#39;COLUMN2&#39;, &#39;COLUMN3&#39;, &#39;COLUMN4&#39;, &#39;COLUMN5&#39;], [&#39;1&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;CB&#39;, &#39;CC&#39;], [&#39;2&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;FB&#39;, &#39;FC&#39;], [&#39;3&#39;, &#39;G&#39;, &#39;9999999999999&#39;, &#39;I&#39;, &#39;IB&#39;, &#39;IC&#39;], [&#39;4&#39;, &#39;!&#39;, &#39;@&#39;, &#39;#&#39;, &#39;$&#39;, &#39;%&#39;], ] . Very Basic Tabulate Table (no headers) . The simplest form of table just involves passing a list of lists into a tabulate call. | The result is not very pretty, but we just dropped from upwards of 30+ lines of code to... ONE LINE. | . from tabulate import tabulate print(tabulate(table_list)) . -- - - - - - INDEX COLUMN1 COLUMN2 COLUMN3 COLUMN4 COLUMN5 1 A B C CB CC 2 D E F FB FC 3 G 9999999999999 I IB IC 4 ! @ # $ % -- - - - - - . Basic Tabulate Table with Headers . The first example was nice and easy, but it didn&#39;t separate the header list from the data. | Tabulate allows headers to be set using using a headers parameter. | In the example below, notice the headers list was also removed from table_list (otherwise they would show up twice). | . print(tabulate(table_list[1:], headers=[&#39;INDEX&#39;, &#39;COLUMN1&#39;, &#39;COLUMN2&#39;, &#39;COLUMN3&#39;, &#39;COLUMN4&#39;, &#39;COLUMN5&#39;])) . INDEX COLUMN1 COLUMN2 COLUMN3 COLUMN4 COLUMN5 - - 1 A B C CB CC 2 D E F FB FC 3 G 9999999999999 I IB IC 4 ! @ # $ % . Typing out all of the headers can be tedious. | Fortunately an exiting list object can be passed into the headers parameter, and a headers list already exists: table_list[0] | Below is a cleaned up example with the header list sliced out of table_list, but added to headers | . print(tabulate(table_list[1:], headers=table_list[0])) . INDEX COLUMN1 COLUMN2 COLUMN3 COLUMN4 COLUMN5 - - 1 A B C CB CC 2 D E F FB FC 3 G 9999999999999 I IB IC 4 ! @ # $ % . Similar how headers functions, a raw list can also be typed out in parameter position 1 as well (rather than passing in an existing list object). | . Tabulate Table with Index . It&#39;s also easy to add an index (our example has one manually created, but this can be useful as well). | . print(tabulate(table_list[1:], headers=table_list[0], showindex=&quot;always&quot;)) . INDEX COLUMN1 COLUMN2 COLUMN3 COLUMN4 COLUMN5 -- - - 0 1 A B C CB CC 1 2 D E F FB FC 2 3 G 9999999999999 I IB IC 3 4 ! @ # $ % . Tabulate Table Formats . One of the nicest features of tabulate is that it has a large number of formats available | . print(tabulate(table_list[1:], headers=table_list[0], tablefmt=&quot;github&quot;)) . | INDEX | COLUMN1 | COLUMN2 | COLUMN3 | COLUMN4 | COLUMN5 | ||--||--|--|--| | 1 | A | B | C | CB | CC | | 2 | D | E | F | FB | FC | | 3 | G | 9999999999999 | I | IB | IC | | 4 | ! | @ | # | $ | % | . print(tabulate(table_list[1:], headers=table_list[0], tablefmt=&quot;grid&quot;)) . ++--++--+--+--+ | INDEX | COLUMN1 | COLUMN2 | COLUMN3 | COLUMN4 | COLUMN5 | +=========+===========+===============+===========+===========+===========+ | 1 | A | B | C | CB | CC | ++--++--+--+--+ | 2 | D | E | F | FB | FC | ++--++--+--+--+ | 3 | G | 9999999999999 | I | IB | IC | ++--++--+--+--+ | 4 | ! | @ | # | $ | % | ++--++--+--+--+ . print(tabulate(table_list[1:], headers=table_list[0], tablefmt=&quot;fancy_grid&quot;)) . ╒═════════╤═══════════╤═══════════════╤═══════════╤═══════════╤═══════════╕ │ INDEX │ COLUMN1 │ COLUMN2 │ COLUMN3 │ COLUMN4 │ COLUMN5 │ ╞═════════╪═══════════╪═══════════════╪═══════════╪═══════════╪═══════════╡ │ 1 │ A │ B │ C │ CB │ CC │ ├─────────┼───────────┼───────────────┼───────────┼───────────┼───────────┤ │ 2 │ D │ E │ F │ FB │ FC │ ├─────────┼───────────┼───────────────┼───────────┼───────────┼───────────┤ │ 3 │ G │ 9999999999999 │ I │ IB │ IC │ ├─────────┼───────────┼───────────────┼───────────┼───────────┼───────────┤ │ 4 │ ! │ @ │ # │ $ │ % │ ╘═════════╧═══════════╧═══════════════╧═══════════╧═══════════╧═══════════╛ . print(tabulate(table_list[1:], headers=table_list[0], tablefmt=&quot;psql&quot;)) . ++--++--+--+--+ | INDEX | COLUMN1 | COLUMN2 | COLUMN3 | COLUMN4 | COLUMN5 | |+--++--+--+--| | 1 | A | B | C | CB | CC | | 2 | D | E | F | FB | FC | | 3 | G | 9999999999999 | I | IB | IC | | 4 | ! | @ | # | $ | % | ++--++--+--+--+ . Summary . It&#39;s very helpful to know the basics of how a plain text table can be constructed | Once that concept is understood, it&#39;s also very helpful to have a tool that does most of the work for you. | In the github link further above, documentation exists showing that the tabulate library contains a lot of functionality not shown here, as well as a number of additional formatting options. | .",
            "url": "https://darrida.com/general/2020/11/23/Print-Simple-Tables.html",
            "relUrl": "/general/2020/11/23/Print-Simple-Tables.html",
            "date": " • Nov 23, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Tranforming and Flattening Data",
            "content": "The Situation . A while back I had a the need to take what were essentially audit logs, where multiple records existed for each id, and flatten then into a single record for each id. . I pulled the data into python from a database as a list of over 100,000 tuples. Here is an example of the data I was looking at. . csv (audit_record.csv) RECORD,ID,OLD_VALUE,FINAL_VALUE,DATE,TABLE,COLUMN 1, id1, value1, value2, 02/01/2020, table1, column1 2, id1, value2, value3, 02/02/2020, table1, column1 3, id1, value3, value1, 02/03/2020, table1, column1 4, id2, value4, value5, 02/01/2020, table1, column1 5, id2, value5, , 02/03/2020, table1, column1 6, id3, value6, value7, 02/01/2020, table1, column1 7, id3, value8, value9, 02/02/2020, table1, column1 8, id4, value10, value11, 02/01/2020, table1, column1 9, id4, value11, value12, 02/02/2020, table1, column1 10,id4, value12, value4, 02/03/2020, table1, column1 . The Problem . This was an audit log for a series of undesired changes. Here is an example of the progression of these changes: . 02/01/2020: a large number of records were changed and iterated to the next highest available number | 02/02/2020: a similar number of records (but not all) were changed again, again iterating to the next available number | 02/03/2020: an additional event took place that resulted in many of the records being corrected (returning to their previous numbers), but some ended at yet another iteration higher, while still others ended up missing a value altogether. | . In the sample information above there are 4 different unintended transformations of data that occurred: . id1: Example series of changes that ended back at the correct value: . 02/01: value1 =&gt; value2 | 02/02: value2 =&gt; value3 | 02/03: value3 =&gt; value1 . id2: Example of series of changes that ended with a complete removal of the value: . 02/01: value4 =&gt; value5 | 02/02: No Changes | 02/03: value5 =&gt; null . id3: Example of series of changes that ended at a different number: . 02/01: value6 =&gt; value7 | 02/02: value7 =&gt; value8 | 02/03: No Changes . id4: Example of series of changes that ended up a different id&#39;s value (data not only incorrect, but conflicting): . 02/01: value10 =&gt; value11 | 02/02: value11 =&gt; value12 | 02/03: value12 =&gt; value4 . Details . In addition to the obvious differences between these 4 different changes, there are some that are harder to see: . Some id records went through 3 changes, others went through 2 (this one is not hard to see) | The last change of some id records was on 02/02, while others&#39; last change was on 02/03 | . Altogether, the different factors that need to be understood are the following: . Some records changed each of the 3 days, some only on 2 | Some of the records that only changed 2 times had their final changed on day 2, while others skipped day 2 and had their final change on day 3 | Some records eventually were self corrected to their original value | Some records iterated 2 times and ended at a different number | Some records eventually ended up with a final value of null | Some records ended up at the original value of a different id | . This example, as messy as it is, also is cleaner that the situation itself. The follow challenges existed: . There were some that only had 1 audit record where the original value was immediately replaced with a null | The list of tuples was not sorted in any fashion | The dates were actually spread over a period of 14 or 15 days, with the changes for a single record following anywhere in that time period -- not a clean 3 days like the example here. | . The tuples that represent the audits for these changes are all over the place. In the end, what I wanted to see clearly what I was dealing with. In order to do that I needed to have a list of new records that would clearly show me the following for each id: . original value, and the date that value was lost | final value, and the date that value was added | . The Solution . Gather the change associated with a single id together, identified by that id: | . import csv from collections import defaultdict reader = csv.DictReader(open(&#39;2020-06-08/audit_record.csv&#39;)) dict_by_user = defaultdict(list) for i in reader: dict_by_user[i[&#39;ID&#39;]].append(i) . The results in dcit_by_user are the following data structure (python dictionary) | . dict_by_user = { &#39;id1&#39;: [[&#39;id1&#39;, &#39;value1&#39;, &#39;value2&#39;, &#39;02/01/2020&#39;, &#39;table1&#39;, &#39;column1&#39;], [&#39;id1&#39;, &#39;value2&#39;, &#39;value3&#39;, &#39;02/02/2020&#39;, &#39;table1&#39;, &#39;column1&#39;], [&#39;id1&#39;, &#39;value3&#39;, &#39;value1&#39;, &#39;02/03/2020&#39;, &#39;table1&#39;, &#39;column1&#39;]], &#39;id2&#39;: [[&#39;id2&#39;, &#39;value4&#39;, &#39;value5&#39;, &#39;02/01/2020&#39;, &#39;table1&#39;, &#39;column1&#39;], [&#39;id2&#39;, &#39;value5&#39;, &#39;&#39;, &#39;02/03/2020,&#39; &#39;table1&#39;, &#39;column1&#39;]], &#39;id3&#39;: [[&#39;id3&#39;, &#39;value6&#39;, &#39;value7&#39;, &#39;02/01/2020&#39;, &#39;table1&#39;, &#39;column1&#39;], [&#39;id3&#39;, &#39;value8&#39;, &#39;value9&#39;, &#39;02/02/2020&#39;, &#39;table1&#39;, &#39;column1&#39;]], &#39;id4&#39;: [[&#39;id4&#39;, &#39;value10&#39;,&#39;value11&#39;, &#39;02/01/2020&#39;, &#39;table1&#39;, &#39;column1&#39;], [&#39;id4&#39;, &#39;value11&#39;,&#39;value12&#39;, &#39;02/02/2020&#39;, &#39;table1&#39;, &#39;column1&#39;], [&#39;id4&#39;, &#39;value12&#39;,&#39;value4&#39;, &#39;02/03/2020&#39;, &#39;table1&#39;, &#39;column1&#39;]] } . NOTE: The actual end result of a defaultdict. The more accurate representation of what the data looks like can be seen by expanding the result right below here. | . #collapse-hide dict_by_user = defaultdict(&lt;class &#39;list&#39;&gt;, {&#39; id1&#39;: [OrderedDict([(&#39;RECORD&#39;, &#39;1&#39;), (&#39;ID&#39;, &#39; id1&#39;), (&#39;OLD_VALUE&#39;, &#39;value1&#39;), (&#39;FINAL_VALUE&#39;, &#39;value2&#39;), (&#39;DATE&#39;, &#39;02/01/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;)]), OrderedDict([(&#39;RECORD&#39;, &#39;2&#39;), (&#39;ID&#39;, &#39; id1&#39;), (&#39;OLD_VALUE&#39;, &#39;value2&#39;), (&#39;FINAL_VALUE&#39;, &#39;value3&#39;), (&#39;DATE&#39;, &#39;02/02/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;)]), OrderedDict([(&#39;RECORD&#39;, &#39;3&#39;), (&#39;ID&#39;, &#39; id1&#39;), (&#39;OLD_VALUE&#39;, &#39;value1&#39;), (&#39;FINAL_VALUE&#39;, &#39;value1&#39;), (&#39;DATE&#39;, &#39;02/03/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;), (&#39;ORIGINAL_DATE&#39;, &#39;02/01/2020&#39;)])], &#39; id2&#39;: [OrderedDict([(&#39;RECORD&#39;, &#39;4&#39;), (&#39;ID&#39;, &#39; id2&#39;), (&#39;OLD_VALUE&#39;, &#39;value4&#39;), (&#39;FINAL_VALUE&#39;, &#39;value5&#39;), (&#39;DATE&#39;, &#39;02/01/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;)]), OrderedDict([(&#39;RECORD&#39;, &#39;5&#39;), (&#39;ID&#39;, &#39; id2&#39;), (&#39;OLD_VALUE&#39;, &#39;value4&#39;), (&#39;FINAL_VALUE&#39;, &#39;&#39;), (&#39;DATE&#39;, &#39;02/03/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;), (&#39;ORIGINAL_DATE&#39;, &#39;02/01/2020&#39;)])], &#39; id3&#39;: [OrderedDict([(&#39;RECORD&#39;, &#39;6&#39;), (&#39;ID&#39;, &#39; id3&#39;), (&#39;OLD_VALUE&#39;, &#39;value6&#39;), (&#39;FINAL_VALUE&#39;, &#39;value7&#39;), (&#39;DATE&#39;, &#39;02/01/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;)]), OrderedDict([(&#39;RECORD&#39;, &#39;7&#39;), (&#39;ID&#39;, &#39; id3&#39;), (&#39;OLD_VALUE&#39;, &#39;value6&#39;), (&#39;FINAL_VALUE&#39;, &#39;value9&#39;), (&#39;DATE&#39;, &#39;02/02/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;), (&#39;ORIGINAL_DATE&#39;, &#39;02/01/2020&#39;)])], &#39; id4&#39;: [OrderedDict([(&#39;RECORD&#39;, &#39;8&#39;), (&#39;ID&#39;, &#39; id4&#39;), (&#39;OLD_VALUE&#39;, &#39;value10&#39;), (&#39;FINAL_VALUE&#39;, &#39;value11&#39;), (&#39;DATE&#39;, &#39;02/01/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;)]), OrderedDict([(&#39;RECORD&#39;, &#39;9&#39;), (&#39;ID&#39;, &#39; id4&#39;), (&#39;OLD_VALUE&#39;, &#39;value10&#39;), (&#39;FINAL_VALUE&#39;, &#39;value12&#39;), (&#39;DATE&#39;, &#39;02/02/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;), (&#39;ORIGINAL_DATE&#39;, &#39;02/01/2020&#39;)])], &#39;id4&#39;: [OrderedDict([(&#39;RECORD&#39;, &#39;10&#39;), (&#39;ID&#39;, &#39;id4&#39;), (&#39;OLD_VALUE&#39;, &#39;value12&#39;), (&#39;FINAL_VALUE&#39;, &#39;value4&#39;), (&#39;DATE&#39;, &#39;02/03/2020&#39;), (&#39;TABLE&#39;, &#39; table1&#39;), (&#39;COLUMN&#39;, &#39; column1&#39;), (&#39;ORIGINAL_DATE&#39;, &#39;02/03/2020&#39;)])]}) . . dict_by_user is then passed into the next section: | . audit_summary_l = [] for i in dict_by_user: if dict_by_user: temp_dict = {} max = &#39;0&#39; min = &#39;99/99/9999&#39; for record in dict_by_user[i]: if record[&#39;DATE&#39;] &gt; max: max = record[&#39;DATE&#39;] last = record if record[&#39;DATE&#39;] &lt; min: min = record[&#39;DATE&#39;] first = record temp_dict = last temp_dict[&#39;OLD_VALUE&#39;] = first[&#39;OLD_VALUE&#39;] temp_dict[&#39;ORIGINAL_DATE&#39;] = first[&#39;DATE&#39;] audit_summary_l.append(temp_dict) columns = [&#39;ID&#39;,&#39;OLD_VALUE&#39;,&#39;ORIGINAL_DATE&#39;,&#39;FINAL_VALUE&#39;, &#39;DATE&#39;,&#39;TABLE&#39;,&#39;COLUMN&#39;,&#39;RECORD&#39;] with open(&#39;2020-06-08/audit_summary.csv&#39;, &#39;w&#39;) as output_file: dict_writer = csv.DictWriter(output_file, fieldnames=columns, lineterminator=&#39; n&#39;) dict_writer.writeheader() for data in audit_summary_l: dict_writer.writerow(data) . This results in the following csv data: | . csv ID,OLD_VALUE,ORIGINAL_DATE,FINAL_VALUE,DATE,TABLE,COLUMN,RECORD id1, value1, 02/01/2020, value1, 02/03/2020, table1,column1, 3 id2, value4, 02/01/2020, , 02/03/2020, table1,column1, 5 id3, value6, 02/01/2020, value9, 02/02/2020, table1,column1, 7 id4, value10, 02/01/2020, value4, 02/03/2020,table 1,column1, 10 .",
            "url": "https://darrida.com/csv/defaultdict/2020/06/08/Transforming-and-Flattening-Data.html",
            "relUrl": "/csv/defaultdict/2020/06/08/Transforming-and-Flattening-Data.html",
            "date": " • Jun 8, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Microsoft Word Example Post",
            "content": "When writing a blog post with Microsoft Word – the filename becomes the title. In this case the file name is “2020-01-01-Microsoft-Word-Example-Post.docx”. . There is minimal support for Word documents in fastpages compared to Jupyter notebooks. Some known limitations: . alt text in Word documents are not yet supported by fastpages, and will break links to images. . | You can only specify front matter for Word documents globally. See the README for more details. . | . For greater control over the content produced from Word documents, you will need to convert Word to markdown files manually. You can follow the steps in this blog post, which walk you through how to use pandoc to do the conversion. Note: If you wish to customize your Word generated blog post in markdown, make sure you delete your Word document from the _word directory so your markdown file doesn’t get overwritten! . If your primary method of writing blog posts is Word documents, and you plan on always manually editing Word generated markdown files, you are probably better off using fast_template instead of fastpages. . The material below is a reproduction of this blog post, and serves as an illustrative example. . Maintaining a healthy open source project can entail a huge amount of toil. Popular projects often have orders of magnitude more users and episodic contributors opening issues and PRs than core maintainers capable of handling these issues. . Consider this graphic prepared by the NumFOCUS foundation showing the number of maintainers for three widely used scientific computing projects: . . We can see that across these three projects, there is a very low ratio maintainers to users. Fixing this problem is not an easy task and likely requires innovative solutions to address the economics as well as tools. . Due to its recent momentum and popularity, Kubeflow suffers from a similar fate as illustrated by the growth of new issues opened: . . Source: “TensorFlow World 2019, Automating Your Developer Workflow With ML” . Coincidentally, while building out end to end machine learning examples for Kubeflow, we built two examples using publicly available GitHub data: GitHub Issue Summarization and Code Search. While these tutorials were useful for demonstrating components of Kubeflow, we realized that we could take this a step further and build concrete data products that reduce toil for maintainers. . This is why we started the project kubeflow/code-intelligence, with the goals of increasing project velocity and health using data driven tools. Below are two projects we are currently experimenting with : . Issue Label Bot: This is a bot that automatically labels GitHub issues using Machine Learning. This bot is a GitHub App that was originally built for Kubeflow but is now also used by several large open source projects. The current version of this bot only applies a very limited set of labels, however we are currently A/B testing new models that allow personalized labels. Here is a blog post discussing this project in more detail. . | Issue Triage GitHub Action: to compliment the Issue Label Bot, we created a GitHub Action that automatically adds / removes Issues to the Kubeflow project board tracking issues needing triage. . | Together these projects allow us to reduce the toil of triaging issues. The GitHub Action makes it much easier for the Kubeflow maintainers to track issues needing triage. With the label bot we have taken the first steps in using ML to replace human intervention. We plan on using features extracted by ML to automate more steps in the triage process to further reduce toil. . Building Solutions with GitHub Actions . One of the premises of Kubeflow is that a barrier to building data driven, ML powered solutions is getting models into production and integrated into a solution. In the case of building models to improve OSS project health, that often means integrating with GitHub where the project is hosted. . We are really excited by GitHub’s newly released feature GitHub Actions because we think it will make integrating ML with GitHub much easier. . For simple scripts, like the issue triage script, GitHub actions make it easy to automate executing the script in response to GitHub events without having to build and host a GitHub app. . To automate adding/removing issues needing triage to a Kanban board we wrote a simple python script that interfaces with GitHub’s GraphQL API to modify issues. . As we continue to iterate on ML Models to further reduce toil, GitHub Actions will make it easy to leverage Kubeflow to put our models into production faster. A number of prebuilt GitHub Actions make it easy to create Kubernetes resources in response to GitHub events. For example, we have created GitHub Actions to launch Argo Workflows. This means once we have a Kubernetes job or workflow to perform inference we can easily integrate the model with GitHub and have the full power of Kubeflow and Kubernetes (eg. GPUs). We expect this will allow us to iterate much faster compared to building and maintaining GitHub Apps. . Call To Action . We have a lot more work to do in order to achieve our goal of reducing the amount of toil involved in maintaining OSS projects. If your interested in helping out here’s a couple of issues to get started: . Help us create reports that pull and visualize key performance indicators (KPI). https://github.com/kubeflow/code-intelligence/issues/71 . We have defined our KPI here: issue #19 | . | Combine repo specific and non-repo specific label predictions: https://github.com/kubeflow/code-intelligence/issues/70 . | . In addition to the aforementioned issues we welcome contributions for these other issues in our repo. .",
            "url": "https://darrida.com/2020/01/01/Microsoft-Word-Example-Post.html",
            "relUrl": "/2020/01/01/Microsoft-Word-Example-Post.html",
            "date": " • Jan 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://darrida.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://darrida.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}